{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615580c8",
   "metadata": {},
   "source": [
    "asdf\n",
    "\n",
    "# Evolutionäres Lernen\n",
    "## Grundidee\n",
    "Evolutionäres Lernen (EL) ist eine Klasse von Optimierungs- und Lernverfahren, die sich an biologischer Evolution orientieren.\n",
    "Zentrale Metapher:\n",
    "„Wir lassen viele Lösungen gegeneinander antreten, selektieren die besten und erzeugen daraus neue Generationen.“\n",
    "\n",
    "Es ist modellfrei, gradientenfrei und funktioniert besonders gut in hochdimensionalen, nicht-differenzierbaren oder verrauschten Umgebungen.\n",
    "\n",
    "## Die drei Grundbausteine\n",
    "1. Variation\n",
    "Neue Kandidatenlösungen werden erzeugt durch:\n",
    "- Mutation (kleine zufällige Änderungen)\n",
    "- Rekombination (Kombination zweier Eltern)\n",
    "- Sampling aus Verteilungen\n",
    "\n",
    "„Wir werfen viele neue Ideen in den Raum.“\n",
    "\n",
    "\n",
    "2. Selektion\n",
    "Die besten Individuen werden anhand einer Fitnessfunktion ausgewählt.\n",
    "\n",
    "„Wir behalten, was funktioniert.“\n",
    "\n",
    "\n",
    "3. Vererbung\n",
    "Die guten Lösungen erzeugen die nächste Generation.\n",
    "\n",
    "„Erfolgreiche Strategien pflanzen sich fort.“\n",
    "\n",
    "\n",
    "## Genetische Algorithmen (GA)\n",
    "- Population von Bitstrings oder Parametern\n",
    "- Mutation + Crossover\n",
    "- Sehr anschaulich, ideal für erste Beispiele\n",
    "\n",
    "Perfekt für den Einstieg, weil der Mechanismus intuitiv ist.\n",
    "\n",
    "## Evolution Strategies (ES)\n",
    "- Arbeiten mit reellen Parametern\n",
    "- Fokus auf Mutation statt Crossover\n",
    "- Sehr gut für kontinuierliche Optimierung\n",
    "Bekannte Varianten:\n",
    "- (1+1)-ES\n",
    "- (μ, λ)-ES\n",
    "- CMA‑ES (Covariance Matrix Adaptation)\n",
    "\n",
    "Zeigt, wie man ohne Gradienten in hochdimensionalen Räumen optimiert.\n",
    "\n",
    "## Neuroevolution\n",
    "Optimiert Neuronale Netze statt einzelner Parameter.\n",
    "Varianten:\n",
    "- NEAT (NeuroEvolution of Augmenting Topologies)\n",
    "→ entwickelt gleichzeitig Topologie und Gewichte\n",
    "- ES für Policy‑Optimierung\n",
    "→ OpenAI ES als prominentes Beispiel\n",
    "\n",
    "Ideal, um RL ohne Gradienten zu erklären.\n",
    "\n",
    "## Genetische Programmierung (GP)\n",
    "- Evolution von Programmen oder Bäumen\n",
    "- Symbolische Regression, Regelgenerierung\n",
    "\n",
    "Zeigt, dass Evolution nicht nur Zahlen, sondern auch Strukturen optimieren kann.\n",
    "\n",
    "## Evolutionäres Lernen vs. Reinforcement Learning \n",
    "\n",
    "| Aspekt                     | Evolutionäres Lernen (EL)                     | Reinforcement Learning (RL)                         |\n",
    "|---------------------------|------------------------------------------------|-----------------------------------------------------|\n",
    "| Optimierungsprinzip       | populationsbasiert, gradientenfrei            | wertbasiert oder gradientenbasiert                 |\n",
    "| Datenbedarf               | hoch                                           | moderat bis hoch                                   |\n",
    "| Robustheit                | sehr hoch                                      | abhängig von Hyperparametern                       |\n",
    "| Differenzierbarkeit       | nicht erforderlich                             | oft erforderlich                                   |\n",
    "| Parallelisierbarkeit      | extrem gut                                     | begrenzt                                           |\n",
    "| Exploration               | eingebaut durch Mutation & Variation           | muss explizit gestaltet werden                     |\n",
    "| Lernstabilität            | hoch                                           | kann instabil sein                                 |\n",
    "| Einsatzgebiete            | Black‑box‑Optimierung, Robotik, Morphologie    | sequentielle Entscheidungen, Kontrolle, Planung    |\n",
    "| Abhängigkeit von Rewards  | Fitnessfunktion bestimmt alles                 | Reward‑Signal + Value/Policy‑Updates               |\n",
    "\n",
    "## Typische Einsatzgebiete\n",
    "- Robotik (z. B. Morphologie + Controller gemeinsam optimieren)\n",
    "- Spiele (z. B. Mario, CarRacing)\n",
    "- Hyperparameter‑Optimierung\n",
    "- Black‑box‑Optimierung\n",
    "- Nicht-differenzierbare oder verrauschte Umgebungen\n",
    "- Multi‑Agent‑Systeme\n",
    "\n",
    "## Wichtige Parameter, die das Verhalten stark beeinflussen\n",
    "| Parameter          | Einflussstärke | Wirkung auf das Verhalten                                   |\n",
    "|--------------------|----------------|--------------------------------------------------------------|\n",
    "| Populationsgröße   | hoch           | bestimmt Diversität, Konvergenzgeschwindigkeit, Rechenaufwand |\n",
    "| Mutationsrate      | hoch           | steuert Exploration; zu hoch = chaotisch, zu niedrig = stagnierend |\n",
    "| Selektionsdruck    | hoch           | hoher Druck = schnelle Konvergenz, aber Risiko von Premature Convergence |\n",
    "| Rekombinationsrate | mittel         | erhöht Vielfalt, kann gute Lösungen kombinieren              |\n",
    "| Fitnessfunktion    | sehr hoch      | definiert das gesamte Lernziel; schlechte Fitness = schlechtes Verhalten |\n",
    "| Anzahl Generationen| mittel         | beeinflusst Reifegrad der Lösungen                           |\n",
    "| Elitismus          | mittel         | stabilisiert Fortschritt, kann aber Vielfalt reduzieren      |\n",
    "\n",
    "„Evolution ist so gut wie ihre Fitnessfunktion.“\n",
    "\n",
    "\n",
    "## Evolution in drei Schritten\n",
    "\n",
    "1. Intuition (Biologie → Algorithmus)\n",
    "- Mutation, Selektion, Vererbung\n",
    "- Beispiel: Optimierung einer einfachen Funktion\n",
    "2. Abstraktion (Algorithmische Bausteine)\n",
    "- Population\n",
    "- Fitness\n",
    "- Variation\n",
    "- Selektion\n",
    "3. Anwendung (Neuroevolution / ES / CMA‑ES)\n",
    "- RL ohne Gradienten\n",
    "- OpenAI ES\n",
    "- Vergleich mit Policy Gradients"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
