ğŸ”· MLP â€“ VollstÃ¤ndig verbundene Schichten
Ein MLP besteht aus:
- Denseâ€‘Layers (jede Neuronâ€‘zuâ€‘Neuronâ€‘Verbindung existiert)
- Keine rÃ¤umliche Strukturannahme
- Input wird als flacher Vektor betrachtet
Konsequenz:
MLPs ignorieren rÃ¤umliche Beziehungen. Ein Pixel an Position (10,10) ist fÃ¼r das Modell nicht nÃ¤her an (10,11) als an (200,200).

ğŸ”¶ CNN â€“ Faltungsschichten mit lokaler Wahrnehmung
Ein CNN nutzt:
- Convolutionâ€‘Kerne (Filter)
- Lokale Rezeptive Felder
- Parameterâ€‘Sharing
- Poolingâ€‘Operationen
Konsequenz:
CNNs erkennen Muster unabhÃ¤ngig von ihrer Position (Translation Invariance) und nutzen die rÃ¤umliche Struktur von Bildern optimal aus.

ğŸ“Š Vergleich CNN vs. MLP
![alt text](compare_mlp_cnn)


ğŸ§© Beispiel: Warum CNNs fÃ¼r Bilder besser sind
Ein 64Ã—64â€‘RGBâ€‘Bild hat:
64\cdot 64\cdot 3=12,288\mathrm{\  Eingabewerte}
Ein MLP mit nur 100 Neuronen in der ersten Schicht hÃ¤tte:
12,288\cdot 100=1,228,800\mathrm{\  Parameter}
Ein CNN mit einem 3Ã—3â€‘Filter und 32 KanÃ¤len hat:
3\cdot 3\cdot 3\cdot 32=864\mathrm{\  Parameter}
â†’ CNN: 864 Parameter vs. MLP: 1.2 Mio.
Das ist der Grund, warum CNNs Bilder so effizient verarbeiten.

ğŸ® RLâ€‘Bezug (da du viel damit arbeitest)
- MLP: Perfekt fÃ¼r CartPole, MountainCar, LunarLander (Zustandsvektor)
- CNN: Pflicht fÃ¼r Atari, MuJoCoâ€‘Kameras, Robotikâ€‘Vision
DQN + CNN ist der Klassiker fÃ¼r Atari.

ğŸ§­ Kurzfassung in einem Satz
MLPs lernen Beziehungen zwischen Features ohne rÃ¤umliche Struktur, wÃ¤hrend CNNs lokale Muster erkennen und rÃ¤umliche ZusammenhÃ¤nge ausnutzen â€“ ideal fÃ¼r Bilder und visuelle RLâ€‘Umgebungen.
